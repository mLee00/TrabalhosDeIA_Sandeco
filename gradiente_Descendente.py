# -*- coding: utf-8 -*-
"""Gradiente_descendente.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f2FH0iZJn8IDvfFfFN8fFQtUj4g6vrBA
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import math

# %matplotlib inline

X = [0.5,2.2, 2.0]
y = [2.0, 2.5, 1.4]

alpha = 0.01 #taxa de aprendizado

#valores iniciais para W0 e W1
w0 = 0.1
w1 = 0.1

#definição da hipótese
def y_hat(x, w0, w1):
  return w0 + w1*x

# realizando uma predição de alto custo
y_hat(1.5, w0, w1)

def plot_line(X,y,w0,w1):
  x_values = [i for i in range(int(min(X))-1, int(max(X)+2))]
  y_values = [y_hat(x,w0,w1)for x in x_values]
  plt.plot(x_values,y_values, 'r')
  plt.plot(X,y,'bo')

plot_line(X,y,w0,w1)

#usando a média do erro**2
def MSE(X,y,w0,w1):
  custo = 0
  m = float(len(X))
  for i in range(0, len(X)):
    custo +=(y_hat(X[i],w0,w1)-y[i])**2
  return custo/m

MSE(X,y,w0,w1)

def gradiente_descentende(w0,w1,X,y, alpha):
  erro_w0 = 0
  erro_w1 = 0
  m = float(len(X))

  for i in range(0, len(X)):
    erro_w0 += y_hat(X[i], w0, w1) - y[i]
    erro_w1 +=(y_hat(X[i], w0, w1) - y[i]) * X[i]

  new_w0 = w0 - alpha * (1/m) * erro_w0
  new_w1 = w1 - alpha * (1/m) * erro_w1

  return new_w0, new_w1

w0, w1 = gradiente_descentende(w0,w1,X,y, alpha)

print("w0 = {}, w1 = {}".format(w0,w1))

epoch = 800

def novoGradiente(w0,w1,X,y,alpha,epoch):
  custo = np.zeros(epoch)
  for i in range (epoch):
    w0, w1 = gradiente_descentende(w0,w1,X,y, alpha)
    custo[i] = MSE (X,y,w0,w1)

  return w0,w1,custo

w0,w1,custo = novoGradiente(w0,w1,X,y, alpha,epoch)

custo

#plotando gráfico do custo
fig,ax = plt.subplots()
ax.plot(np.arange(epoch), custo,'r')
ax.set_xlabel("Interações")
ax.set_ylabel("Custo")
ax.set_title("MSE x Epoch")

plot_line(X,y,w0,w1)

y_hat(1.5,w0,w1)

print("w0 = {}, w1 = {}".format(w0,w1))